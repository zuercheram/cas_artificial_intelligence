{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I11irr61Wujg"
      },
      "source": [
        "# 09. Recurrent Neural Network with PyTorch\n",
        "## 1. About Recurrent Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BTI_mvP85GEm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_nCiHkkWujo"
      },
      "source": [
        "### Step 1: Loading MNIST Train Dataset\n",
        "**Images from 1 to 9**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "metadata": {
        "id": "EtCp6dYaWujo"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as dsets\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {
        "id": "2-aiUtVzDKeq",
        "outputId": "a4139a4c-396d-4a11-a9f1-bffaef9c3c74"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# make the original data\n",
        "ds_length=20_000\n",
        "series = np.sin(0.1*np.arange(ds_length)) + np.cos(2*np.arange(ds_length))+ np.random.randn(ds_length)*0.5\n",
        "\n",
        "# plot it\n",
        "plt.plot(series[:1000])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {
        "id": "cDIbMffYDKer",
        "outputId": "ed453b0f-b63e-4a19-cf14-00836b0401d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X.shape (19900, 100, 1) Y.shape (19900,)\n"
          ]
        }
      ],
      "source": [
        "### build the dataset\n",
        "# let's see if we can use T past values to predict the next value\n",
        "T = 100\n",
        "D = 1\n",
        "X = []\n",
        "Y = []\n",
        "# rolling window\n",
        "for t in range(len(series) - T):\n",
        "    x = series[t:t+T]\n",
        "    X.append(x)\n",
        "    y = series[t+T]\n",
        "    Y.append(y)\n",
        "\n",
        "X = np.array(X).reshape(-1, T, D) # Now the data should be N x T x D\n",
        "Y = np.array(Y)\n",
        "N = len(X)\n",
        "print(\"X.shape\", X.shape, \"Y.shape\", Y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {
        "id": "rSgbuctmDKer",
        "outputId": "389362fb-4835-464a-ac85-45b663e103c8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((9950, 100, 1), (9950,))"
            ]
          },
          "execution_count": 179,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train, Y_train = X[:-N//2], Y[:-N//2]\n",
        "X_test, Y_test = X[-N//2:], Y[-N//2:]\n",
        "X_train.shape, Y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {
        "id": "hG14KWvVDKes"
      },
      "outputs": [],
      "source": [
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "Y_train = torch.tensor(Y_train, dtype=torch.float32).reshape(-1, 1)\n",
        "\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "Y_test = torch.tensor(Y_test, dtype=torch.float32).reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "metadata": {
        "id": "AgNUivxcDKes",
        "outputId": "b73025e7-123a-4c97-c8c9-a1412cd15e90"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([9950, 1])"
            ]
          },
          "execution_count": 181,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCf2b7oJWujs"
      },
      "source": [
        "### Step 2: Make Dataset Iterable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAJ3xO72Wujs",
        "outputId": "2d0b1c6c-fbef-454d-ff21-c61bed0da5fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9\n",
            "torch.Size([16, 100, 1]) torch.Size([16, 1])\n"
          ]
        }
      ],
      "source": [
        "batch_size = 16\n",
        "n_iters = 12000\n",
        "num_epochs = n_iters // (len(series) // batch_size)\n",
        "print(num_epochs)\n",
        "num_epochs = int(num_epochs)\n",
        "\n",
        "# train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "#                                           batch_size=batch_size,\n",
        "#                                           shuffle=True)\n",
        "\n",
        "# test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "#                                          batch_size=batch_size,\n",
        "#                                          shuffle=False)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(list(zip(X_train, Y_train)), shuffle=True, batch_size=batch_size)\n",
        "test_loader = torch.utils.data.DataLoader(list(zip(X_test, Y_test)), shuffle=False, batch_size=batch_size)\n",
        "for X_batch, y_batch in train_loader:\n",
        "    print(X_batch.shape, y_batch.shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {
        "id": "JahbnBYBWujs"
      },
      "outputs": [],
      "source": [
        "class RNNModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
        "        super(RNNModel, self).__init__()\n",
        "        # Hidden dimensions\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        # Number of hidden layers\n",
        "        self.layer_dim = layer_dim\n",
        "\n",
        "        # Building your RNN\n",
        "        # batch_first=True causes input/output tensors to be of shape\n",
        "        # (batch_dim, seq_dim, input_dim)\n",
        "        self.rnn = nn.RNN(input_dim, hidden_dim, layer_dim, batch_first=True, nonlinearity='relu') #\n",
        "\n",
        "        # Readout layer\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Initialize hidden state with zeros\n",
        "        # (layer_dim, batch_size, hidden_dim)\n",
        "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_()\n",
        "\n",
        "        # We need to detach the hidden state to prevent exploding/vanishing gradients\n",
        "        # This is part of truncated backpropagation through time (BPTT)\n",
        "        out, hn = self.rnn(x, h0.detach())\n",
        "\n",
        "        # Index hidden state of last time step\n",
        "        # out.size() --> 100, 28, 10\n",
        "        # out[:, -1, :] --> 100, 10 --> just want last time step hidden states!\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        # out.size() --> 100, 10\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZtoWNi9Wujt"
      },
      "source": [
        "### Step 4: Instantiate Model Class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjZPMZKCWujt"
      },
      "source": [
        "- 28 time steps\n",
        "    - Each time step: input dimension = 28\n",
        "- 1 hidden layer\n",
        "- MNIST 0-9 digits $\\rightarrow$ output dimension = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "metadata": {
        "id": "bBn8zlGfWujt"
      },
      "outputs": [],
      "source": [
        "input_dim = 1\n",
        "hidden_dim = 32\n",
        "layer_dim = 2\n",
        "output_dim = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "metadata": {
        "id": "h0BzbsgzWujt"
      },
      "outputs": [],
      "source": [
        "model = RNNModel(input_dim, hidden_dim, layer_dim, output_dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLhGS297jv4b",
        "outputId": "85ab8065-c71b-4123-a14d-68932e349d55"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RNNModel(\n",
              "  (rnn): RNN(1, 32, num_layers=2, batch_first=True)\n",
              "  (fc): Linear(in_features=32, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 186,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "7x-0anEIWuju"
      },
      "source": [
        "### Step 5: Instantiate Loss Class\n",
        "- Recurrent Neural Network: **Cross Entropy Loss**\n",
        "    - _Convolutional Neural Network_: **Cross Entropy Loss**\n",
        "    - _Feedforward Neural Network_: **Cross Entropy Loss**\n",
        "    - _Logistic Regression_: **Cross Entropy Loss**\n",
        "    - _Linear Regression_: **MSE**\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "metadata": {
        "id": "eRqU5RUKWuju"
      },
      "outputs": [],
      "source": [
        "criterion = nn.MSELoss() #nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzcme_SlidZI"
      },
      "source": [
        "$\\theta = \\theta - \\eta \\cdot \\nabla_\\theta$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOqoAX6LWuju"
      },
      "source": [
        "### Step 6: Instantiate Optimizer Class\n",
        "Simplified equation:\n",
        "\n",
        "$\\theta = \\theta - \\eta \\cdot \\nabla_\\theta$\n",
        "\n",
        "$\\theta$: parameters (our tensors with gradient accumulation abilities)\n",
        "\n",
        "$\\eta$: learning rate (how fast we want to learn)\n",
        "\n",
        "$\\nabla_\\theta$: parameters' gradients\n",
        "\n",
        "\n",
        "\n",
        "- Even simplier equation\n",
        "    - `parameters = parameters - learning_rate * parameters_gradients`\n",
        "    - **At every iteration, we update our model's parameters**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 188,
      "metadata": {
        "id": "Ktr8uGx7Wuju"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.001\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxm_xsfOWuj0"
      },
      "source": [
        "### Step 7: Train Model\n",
        "- Process\n",
        "    1. **Convert inputs/labels to tensors with gradient accumulation abilities**\n",
        "        - RNN Input: (1, 28)\n",
        "        - CNN Input: (1, 28, 28)\n",
        "        - FNN Input: (1, 28*28)\n",
        "    2. Clear gradient buffets\n",
        "    3. Get output given inputs\n",
        "    4. Get loss\n",
        "    5. Get gradients w.r.t. parameters\n",
        "    6. Update parameters using gradients\n",
        "        - `parameters = parameters - learning_rate * parameters_gradients`\n",
        "    7. REPEAT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 189,
      "metadata": {
        "id": "n_vmlWZKDKfD",
        "outputId": "730fd29e-311e-4b21-bc1b-77c1a2101b93"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "execution_count": 189,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "num_epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 190,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIRPTqFMWuj0",
        "outputId": "26ebf752-d046-4fbc-826e-532057736a2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration: 500. Train Loss: 0.5472568869590759. Test_loss: 0.30293649435043335\n",
            "Iteration: 1000. Train Loss: 0.4827612638473511. Test_loss: 0.30816617608070374\n",
            "Iteration: 1500. Train Loss: 0.35012438893318176. Test_loss: 0.26453897356987\n",
            "Iteration: 2000. Train Loss: 0.2864071726799011. Test_loss: 0.28012344241142273\n",
            "Iteration: 2500. Train Loss: 0.21231910586357117. Test_loss: 0.3195342421531677\n",
            "Iteration: 3000. Train Loss: 0.4252265691757202. Test_loss: 0.2795756757259369\n",
            "Iteration: 3500. Train Loss: 0.21884579956531525. Test_loss: 0.2217680960893631\n",
            "Iteration: 4000. Train Loss: 0.24452224373817444. Test_loss: 0.2416239231824875\n",
            "Iteration: 4500. Train Loss: 0.13883693516254425. Test_loss: 0.31893444061279297\n",
            "Iteration: 5000. Train Loss: 0.43820807337760925. Test_loss: 0.260831743478775\n",
            "Iteration: 5500. Train Loss: 0.21659627556800842. Test_loss: 0.23295088112354279\n"
          ]
        }
      ],
      "source": [
        "# Number of steps to unroll\n",
        "seq_dim = 10\n",
        "\n",
        "iter = 0\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (train_data_points, labels) in enumerate(train_loader):\n",
        "        model.train()\n",
        "        # Load images as tensors with gradient accumulation abilities\n",
        "        # images = images.reshape(-1, seq_dim, input_dim).requires_grad_()\n",
        "\n",
        "        # Clear gradients w.r.t. parameters\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass to get output/logits\n",
        "        # outputs.size() --> 100, 10\n",
        "        outputs = model(train_data_points)\n",
        "\n",
        "        # Calculate Loss: softmax --> cross entropy loss\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Getting gradients w.r.t. parameters\n",
        "        loss.backward()\n",
        "\n",
        "        # Updating parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        iter += 1\n",
        "\n",
        "        if iter % 500 == 0:\n",
        "            model.eval()\n",
        "            # Calculate Accuracy\n",
        "            correct = 0\n",
        "            total = 0\n",
        "            # Iterate through test dataset\n",
        "            for data_points, pred in test_loader:\n",
        "                # Load images to a Torch tensors with gradient accumulation abilities\n",
        "                # images = images.reshape(-1, seq_dim, input_dim)\n",
        "\n",
        "                # Forward pass only to get logits/output\n",
        "                outputs = model(data_points)\n",
        "                test_loss = criterion(outputs, pred)\n",
        "\n",
        "                outputs\n",
        "                # Get predictions from the maximum value\n",
        "                # _, predicted = torch.max(outputs.data, 1) falsch\n",
        "\n",
        "                # Total number of labels\n",
        "                # total += labels.size(0)\n",
        "\n",
        "                # Total correct predictions\n",
        "                # correct += (predicted == labels).sum()\n",
        "\n",
        "            # accuracy = 100 * correct / total\n",
        "\n",
        "            # Print Loss\n",
        "            print('Iteration: {}. Train Loss: {}. Test_loss: {}'.format(iter, loss.item(), test_loss.item()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "zCkKpisEWuj1"
      },
      "source": [
        "### Model B: 2 Hidden Layer (ReLU)\n",
        "- Unroll 28 time steps\n",
        "    - Each step input size: 28 x 1\n",
        "    - Total per unroll: 28 x 28\n",
        "        - Feedforward Neural Network inpt size: 28 x 28\n",
        "- **2 Hidden layer**\n",
        "- ReLU Activation Function\n",
        "\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1_IrmcqLUnAhDRrqy8_Ix4qZ8PUsN9409\" width=\"900\">\n",
        "\n",
        "\n",
        "### Steps\n",
        "- Step 1: Load Dataset\n",
        "- Step 2: Make Dataset Iterable\n",
        "- Step 3: Create Model Class\n",
        "- **Step 4: Instantiate Model Class**\n",
        "- Step 5: Instantiate Loss Class\n",
        "- Step 6: Instantiate Optimizer Class\n",
        "- Step 7: Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 191,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "faGFr7KrWuj1",
        "outputId": "b3452ad7-9535-48d5-c0d9-53c0c157516c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RNNModel(\n",
            "  (rnn): RNN(28, 100, num_layers=2, batch_first=True)\n",
            "  (fc): Linear(in_features=100, out_features=10, bias=True)\n",
            ")\n",
            "10\n",
            "torch.Size([100, 28])\n",
            "torch.Size([100, 100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100, 100])\n",
            "torch.Size([100, 100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([10, 100])\n",
            "torch.Size([10])\n",
            "Iteration: 500. Loss: 0.28856468200683594. Accuracy: 87.83000183105469\n",
            "Iteration: 1000. Loss: 0.27339059114456177. Accuracy: 93.12999725341797\n",
            "Iteration: 1500. Loss: 0.21433515846729279. Accuracy: 94.87999725341797\n",
            "Iteration: 2000. Loss: 0.07946006953716278. Accuracy: 96.0199966430664\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as dsets\n",
        "\n",
        "'''\n",
        "STEP 1: LOADING DATASET\n",
        "'''\n",
        "train_dataset = dsets.MNIST(root='data',\n",
        "                            train=True,\n",
        "                            transform=transforms.ToTensor(),\n",
        "                            download=True)\n",
        "\n",
        "test_dataset = dsets.MNIST(root='data',\n",
        "                           train=False,\n",
        "                           transform=transforms.ToTensor())\n",
        "\n",
        "'''\n",
        "STEP 2: MAKING DATASET ITERABLE\n",
        "'''\n",
        "\n",
        "batch_size = 100\n",
        "n_iters = 3000\n",
        "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
        "num_epochs = int(num_epochs)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)\n",
        "\n",
        "'''\n",
        "STEP 3: CREATE MODEL CLASS\n",
        "'''\n",
        "\n",
        "class RNNModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
        "        super(RNNModel, self).__init__()\n",
        "        # Hidden dimensions\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        # Number of hidden layers\n",
        "        self.layer_dim = layer_dim\n",
        "\n",
        "\n",
        "\n",
        "        # Building your RNN\n",
        "        # batch_first=True causes input/output tensors to be of shape\n",
        "        # (batch_dim, seq_dim, feature_dim)\n",
        "        self.rnn = nn.RNN(input_dim, hidden_dim, layer_dim, batch_first=True, nonlinearity='relu')\n",
        "\n",
        "        # Readout layer\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # Initialize hidden state with zeros\n",
        "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_()\n",
        "\n",
        "        # We need to detach the hidden state to prevent exploding/vanishing gradients\n",
        "        # This is part of truncated backpropagation through time (BPTT)\n",
        "        out, hn = self.rnn(x, h0.detach())\n",
        "\n",
        "        # Index hidden state of last time step\n",
        "        # out.size() --> 100, 28, 100\n",
        "        # out[:, -1, :] --> 100, 100 --> just want last time step hidden states!\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        # out.size() --> 100, 10\n",
        "        return out\n",
        "\n",
        "'''\n",
        "STEP 4: INSTANTIATE MODEL CLASS\n",
        "'''\n",
        "input_dim = 28\n",
        "hidden_dim = 100\n",
        "layer_dim = 2  # ONLY CHANGE IS HERE FROM ONE LAYER TO TWO LAYER\n",
        "output_dim = 10\n",
        "\n",
        "model = RNNModel(input_dim, hidden_dim, layer_dim, output_dim)\n",
        "\n",
        "# JUST PRINTING MODEL & PARAMETERS\n",
        "print(model)\n",
        "print(len(list(model.parameters())))\n",
        "for i in range(len(list(model.parameters()))):\n",
        "    print(list(model.parameters())[i].size())\n",
        "\n",
        "'''\n",
        "STEP 5: INSTANTIATE LOSS CLASS\n",
        "'''\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "'''\n",
        "STEP 6: INSTANTIATE OPTIMIZER CLASS\n",
        "'''\n",
        "learning_rate = 0.001\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "'''\n",
        "STEP 7: TRAIN THE MODEL\n",
        "'''\n",
        "\n",
        "# Number of steps to unroll\n",
        "seq_dim = 28\n",
        "\n",
        "iter = 0\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        model.train()\n",
        "        # Load images as tensors with gradient accumulation abilities\n",
        "        images = images.view(-1, seq_dim, input_dim).requires_grad_()\n",
        "\n",
        "        # Clear gradients w.r.t. parameters\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass to get output/logits\n",
        "        # outputs.size() --> 100, 10\n",
        "        outputs = model(images)\n",
        "\n",
        "        # Calculate Loss: softmax --> cross entropy loss\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Getting gradients w.r.t. parameters\n",
        "        loss.backward()\n",
        "\n",
        "        # Updating parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        iter += 1\n",
        "\n",
        "        if iter % 500 == 0:\n",
        "            model.eval()\n",
        "            # Calculate Accuracy\n",
        "            correct = 0\n",
        "            total = 0\n",
        "            # Iterate through test dataset\n",
        "            for images, labels in test_loader:\n",
        "                # Resize images\n",
        "                images = images.view(-1, seq_dim, input_dim)\n",
        "\n",
        "                # Forward pass only to get logits/output\n",
        "                outputs = model(images)\n",
        "\n",
        "                # Get predictions from the maximum value\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "                # Total number of labels\n",
        "                total += labels.size(0)\n",
        "\n",
        "                # Total correct predictions\n",
        "                correct += (predicted == labels).sum()\n",
        "\n",
        "            accuracy = 100 * correct / total\n",
        "\n",
        "            # Print Loss\n",
        "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgQYe3W3Wuj5"
      },
      "source": [
        "- **10 sets of parameters**\n",
        "- First hidden Layer $A_1 = [100, 28]$\n",
        "    - $A_3 = [100, 100]$\n",
        "    - $B_1 = [100]$\n",
        "    - $B_3 = [100]$\n",
        "- Second hidden layer\n",
        "    - $A_2 = [100, 100]$\n",
        "    - $A_5 = [100, 100]$\n",
        "    - $B_2 = [100]$\n",
        "    - $B_5 = [100]$\n",
        "- Readout layer\n",
        "    - $A_5 = [10, 100]$\n",
        "    - $B_5 = [10]$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rA1Ab1GdWuj7"
      },
      "source": [
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=102CUJIPzNv0QW4o0gXWoDeMA5axwJ9JW\" width=\"900\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "TxzvAhUOWuj7"
      },
      "source": [
        "### Model C: 2 Hidden Layer\n",
        "- Unroll 28 time steps\n",
        "    - Each step input size: 28 x 1\n",
        "    - Total per unroll: 28 x 28\n",
        "        - Feedforward Neural Network inpt size: 28 x 28\n",
        "- 2 Hidden layer\n",
        "- **Tanh** Activation Function\n",
        "\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1QkmuuZ7_-sljD8nzNCHCTufZFybOIHT_\" width=\"900\">\n",
        "\n",
        "### Steps\n",
        "- Step 1: Load Dataset\n",
        "- Step 2: Make Dataset Iterable\n",
        "- Step 3: Create Model Class\n",
        "- **Step 4: Instantiate Model Class**\n",
        "- Step 5: Instantiate Loss Class\n",
        "- Step 6: Instantiate Optimizer Class\n",
        "- Step 7: Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XO0jKqeTWuj7",
        "outputId": "8724d8ba-a701-47ab-e496-4ec1f4d59475"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RNNModel(\n",
            "  (rnn): RNN(28, 100, num_layers=2, batch_first=True)\n",
            "  (fc): Linear(in_features=100, out_features=10, bias=True)\n",
            ")\n",
            "10\n",
            "torch.Size([100, 28])\n",
            "torch.Size([100, 100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([100, 100])\n",
            "torch.Size([100, 100])\n",
            "torch.Size([100])\n",
            "torch.Size([100])\n",
            "torch.Size([10, 100])\n",
            "torch.Size([10])\n",
            "Iteration: 500. Loss: 0.46521714329719543. Accuracy: 80.0999984741211\n",
            "Iteration: 1000. Loss: 0.28643786907196045. Accuracy: 90.12999725341797\n",
            "Iteration: 1500. Loss: 0.23399974405765533. Accuracy: 92.5199966430664\n",
            "Iteration: 2000. Loss: 0.23947027325630188. Accuracy: 93.25\n",
            "Iteration: 2500. Loss: 0.19799625873565674. Accuracy: 94.8499984741211\n",
            "Iteration: 3000. Loss: 0.18210069835186005. Accuracy: 95.43000030517578\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as dsets\n",
        "\n",
        "'''\n",
        "STEP 1: LOADING DATASET\n",
        "'''\n",
        "train_dataset = dsets.MNIST(root='data',\n",
        "                            train=True,\n",
        "                            transform=transforms.ToTensor(),\n",
        "                            download=True)\n",
        "\n",
        "test_dataset = dsets.MNIST(root='data',\n",
        "                           train=False,\n",
        "                           transform=transforms.ToTensor())\n",
        "\n",
        "'''\n",
        "STEP 2: MAKING DATASET ITERABLE\n",
        "'''\n",
        "\n",
        "batch_size = 100\n",
        "n_iters = 3000\n",
        "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
        "num_epochs = int(num_epochs)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)\n",
        "\n",
        "'''\n",
        "STEP 3: CREATE MODEL CLASS\n",
        "'''\n",
        "\n",
        "class RNNModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
        "        super(RNNModel, self).__init__()\n",
        "        # Hidden dimensions\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        # Number of hidden layers\n",
        "        self.layer_dim = layer_dim\n",
        "\n",
        "        # Building your RNN\n",
        "        # batch_first=True causes input/output tensors to be of shape\n",
        "        # (batch_dim, seq_dim, feature_dim)\n",
        "        self.rnn = nn.RNN(input_dim, hidden_dim, layer_dim, batch_first=True, nonlinearity='tanh')\n",
        "\n",
        "        # Readout layer\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Initialize hidden state with zeros\n",
        "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_()\n",
        "\n",
        "        # One time step\n",
        "        # We need to detach the hidden state to prevent exploding/vanishing gradients\n",
        "        # This is part of truncated backpropagation through time (BPTT)\n",
        "        out, hn = self.rnn(x, h0.detach())\n",
        "\n",
        "        # Index hidden state of last time step\n",
        "        # out.size() --> 100, 28, 100\n",
        "        # out[:, -1, :] --> 100, 100 --> just want last time step hidden states!\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        # out.size() --> 100, 10\n",
        "        return out\n",
        "\n",
        "'''\n",
        "STEP 4: INSTANTIATE MODEL CLASS\n",
        "'''\n",
        "input_dim = 28\n",
        "hidden_dim = 100\n",
        "layer_dim = 2  # ONLY CHANGE IS HERE FROM ONE LAYER TO TWO LAYER\n",
        "output_dim = 10\n",
        "\n",
        "model = RNNModel(input_dim, hidden_dim, layer_dim, output_dim)\n",
        "\n",
        "# JUST PRINTING MODEL & PARAMETERS\n",
        "print(model)\n",
        "print(len(list(model.parameters())))\n",
        "for i in range(len(list(model.parameters()))):\n",
        "    print(list(model.parameters())[i].size())\n",
        "\n",
        "'''\n",
        "STEP 5: INSTANTIATE LOSS CLASS\n",
        "'''\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "'''\n",
        "STEP 6: INSTANTIATE OPTIMIZER CLASS\n",
        "'''\n",
        "learning_rate = 0.1\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "'''\n",
        "STEP 7: TRAIN THE MODEL\n",
        "'''\n",
        "\n",
        "# Number of steps to unroll\n",
        "seq_dim = 28\n",
        "\n",
        "iter = 0\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        # Load images as tensors with gradient accumulation abilities\n",
        "        images = images.view(-1, seq_dim, input_dim).requires_grad_()\n",
        "\n",
        "        # Clear gradients w.r.t. parameters\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass to get output/logits\n",
        "        # outputs.size() --> 100, 10\n",
        "        outputs = model(images)\n",
        "\n",
        "        # Calculate Loss: softmax --> cross entropy loss\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Getting gradients w.r.t. parameters\n",
        "        loss.backward()\n",
        "\n",
        "        # Updating parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        iter += 1\n",
        "\n",
        "        if iter % 500 == 0:\n",
        "            # Calculate Accuracy\n",
        "            correct = 0\n",
        "            total = 0\n",
        "            # Iterate through test dataset\n",
        "            for images, labels in test_loader:\n",
        "                # Resize images\n",
        "                images = images.view(-1, seq_dim, input_dim)\n",
        "\n",
        "                # Forward pass only to get logits/output\n",
        "                outputs = model(images)\n",
        "\n",
        "                # Get predictions from the maximum value\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "                # Total number of labels\n",
        "                total += labels.size(0)\n",
        "\n",
        "                # Total correct predictions\n",
        "                correct += (predicted == labels).sum()\n",
        "\n",
        "            accuracy = 100 * correct / total\n",
        "\n",
        "            # Print Loss\n",
        "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJHY7lr1Wuj7"
      },
      "source": [
        "## Summary of Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mbo6ZI5JWuj8"
      },
      "source": [
        "| Model A | Model B   | Model C |\n",
        "|------|------|\n",
        "|   ReLU | ReLU | Tanh |\n",
        "| 1 Hidden Layer | 2 Hidden Layers | 2 Hidden Layers |\n",
        "| 100 Hidden Units | 100 Hidden Units |100 Hidden Units |\n",
        "| 92.48% | 95.09% | 95.54% |\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYs1s-eXWuj8"
      },
      "source": [
        "### Deep Learning\n",
        "- 2 ways to expand a recurrent neural network\n",
        "    - More non-linear activation units (neurons)\n",
        "    - More hidden layers\n",
        "- Cons\n",
        "    - Need a larger dataset\n",
        "        - Curse of dimensionality\n",
        "    - Does not necessarily mean higher accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILdH8dVHWuj8"
      },
      "source": [
        "## 3. Building a Recurrent Neural Network with PyTorch (GPU)\n",
        "\n",
        "### Model C: 2 Hidden Layer (Tanh)\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1QkmuuZ7_-sljD8nzNCHCTufZFybOIHT_\" width=\"900\">\n",
        "\n",
        "\n",
        "GPU: 2 things must be on GPU\n",
        "- `model`\n",
        "- `tensors with gradient accumulation abilities`\n",
        "\n",
        "### Steps\n",
        "- Step 1: Load Dataset\n",
        "- Step 2: Make Dataset Iterable\n",
        "- **Step 3: Create Model Class**\n",
        "- **Step 4: Instantiate Model Class**\n",
        "- Step 5: Instantiate Loss Class\n",
        "- Step 6: Instantiate Optimizer Class\n",
        "- **Step 7: Train Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7bs1swyjWuj8",
        "outputId": "8371d541-761b-469a-b284-4f044000e29e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration: 500. Loss: 0.599184513092041. Accuracy: 78.58999633789062\n",
            "Iteration: 1000. Loss: 0.22469009459018707. Accuracy: 92.7699966430664\n",
            "Iteration: 1500. Loss: 0.12211698293685913. Accuracy: 93.0999984741211\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32mc:\\Repos\\cas-ai\\notebooks\\06_RNN\\06_PyTorch_RNN_Forecasting.ipynb Cell 53\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Repos/cas-ai/notebooks/06_RNN/06_PyTorch_RNN_Forecasting.ipynb#Y103sZmlsZQ%3D%3D?line=122'>123</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Repos/cas-ai/notebooks/06_RNN/06_PyTorch_RNN_Forecasting.ipynb#Y103sZmlsZQ%3D%3D?line=124'>125</a>\u001b[0m \u001b[39m# Forward pass to get output/logits\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Repos/cas-ai/notebooks/06_RNN/06_PyTorch_RNN_Forecasting.ipynb#Y103sZmlsZQ%3D%3D?line=125'>126</a>\u001b[0m \u001b[39m# outputs.size() --> 100, 10\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Repos/cas-ai/notebooks/06_RNN/06_PyTorch_RNN_Forecasting.ipynb#Y103sZmlsZQ%3D%3D?line=126'>127</a>\u001b[0m outputs \u001b[39m=\u001b[39m model(images)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Repos/cas-ai/notebooks/06_RNN/06_PyTorch_RNN_Forecasting.ipynb#Y103sZmlsZQ%3D%3D?line=128'>129</a>\u001b[0m \u001b[39m# Calculate Loss: softmax --> cross entropy loss\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Repos/cas-ai/notebooks/06_RNN/06_PyTorch_RNN_Forecasting.ipynb#Y103sZmlsZQ%3D%3D?line=129'>130</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, labels)\n",
            "File \u001b[1;32mc:\\Users\\amos.zuercher\\.conda\\envs\\ai\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\amos.zuercher\\.conda\\envs\\ai\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
            "\u001b[1;32mc:\\Repos\\cas-ai\\notebooks\\06_RNN\\06_PyTorch_RNN_Forecasting.ipynb Cell 53\u001b[0m line \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Repos/cas-ai/notebooks/06_RNN/06_PyTorch_RNN_Forecasting.ipynb#Y103sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m h0 \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer_dim, x\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhidden_dim)\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Repos/cas-ai/notebooks/06_RNN/06_PyTorch_RNN_Forecasting.ipynb#Y103sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m \u001b[39m# One time step\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Repos/cas-ai/notebooks/06_RNN/06_PyTorch_RNN_Forecasting.ipynb#Y103sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m \u001b[39m# We need to detach the hidden state to prevent exploding/vanishing gradients\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Repos/cas-ai/notebooks/06_RNN/06_PyTorch_RNN_Forecasting.ipynb#Y103sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m \u001b[39m# This is part of truncated backpropagation through time (BPTT)\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Repos/cas-ai/notebooks/06_RNN/06_PyTorch_RNN_Forecasting.ipynb#Y103sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m out, hn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrnn(x, h0\u001b[39m.\u001b[39;49mdetach())\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Repos/cas-ai/notebooks/06_RNN/06_PyTorch_RNN_Forecasting.ipynb#Y103sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m \u001b[39m# Index hidden state of last time step\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Repos/cas-ai/notebooks/06_RNN/06_PyTorch_RNN_Forecasting.ipynb#Y103sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m \u001b[39m# out.size() --> 100, 28, 100\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Repos/cas-ai/notebooks/06_RNN/06_PyTorch_RNN_Forecasting.ipynb#Y103sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m \u001b[39m# out[:, -1, :] --> 100, 100 --> just want last time step hidden states!\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Repos/cas-ai/notebooks/06_RNN/06_PyTorch_RNN_Forecasting.ipynb#Y103sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc(out[:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, :])\n",
            "File \u001b[1;32mc:\\Users\\amos.zuercher\\.conda\\envs\\ai\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\amos.zuercher\\.conda\\envs\\ai\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\amos.zuercher\\.conda\\envs\\ai\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:553\u001b[0m, in \u001b[0;36mRNN.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    551\u001b[0m \u001b[39mif\u001b[39;00m batch_sizes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    552\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mRNN_TANH\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m--> 553\u001b[0m         result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39;49mrnn_tanh(\u001b[39minput\u001b[39;49m, hx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_weights, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_layers,\n\u001b[0;32m    554\u001b[0m                               \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbidirectional,\n\u001b[0;32m    555\u001b[0m                               \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_first)\n\u001b[0;32m    556\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    557\u001b[0m         result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39mrnn_relu(\u001b[39minput\u001b[39m, hx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_weights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers,\n\u001b[0;32m    558\u001b[0m                               \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbidirectional,\n\u001b[0;32m    559\u001b[0m                               \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_first)\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as dsets\n",
        "\n",
        "'''\n",
        "STEP 1: LOADING DATASET\n",
        "'''\n",
        "train_dataset = dsets.MNIST(root='data',\n",
        "                            train=True,\n",
        "                            transform=transforms.ToTensor(),\n",
        "                            download=True)\n",
        "\n",
        "test_dataset = dsets.MNIST(root='data',\n",
        "                           train=False,\n",
        "                           transform=transforms.ToTensor())\n",
        "\n",
        "'''\n",
        "STEP 2: MAKING DATASET ITERABLE\n",
        "'''\n",
        "\n",
        "batch_size = 100\n",
        "n_iters = 3000\n",
        "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
        "num_epochs = int(num_epochs)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)\n",
        "\n",
        "'''\n",
        "STEP 3: CREATE MODEL CLASS\n",
        "'''\n",
        "\n",
        "class RNNModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
        "        super(RNNModel, self).__init__()\n",
        "        # Hidden dimensions\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        # Number of hidden layers\n",
        "        self.layer_dim = layer_dim\n",
        "\n",
        "        # Building your RNN\n",
        "        # batch_first=True causes input/output tensors to be of shape\n",
        "        # (batch_dim, seq_dim, feature_dim)\n",
        "        self.rnn = nn.RNN(input_dim, hidden_dim, layer_dim, batch_first=True, nonlinearity='tanh')\n",
        "\n",
        "        # Readout layer\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Initialize hidden state with zeros\n",
        "        #######################\n",
        "        #  USE GPU FOR MODEL  #\n",
        "        #######################\n",
        "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).to(device)\n",
        "\n",
        "        # One time step\n",
        "        # We need to detach the hidden state to prevent exploding/vanishing gradients\n",
        "        # This is part of truncated backpropagation through time (BPTT)\n",
        "        out, hn = self.rnn(x, h0.detach())\n",
        "\n",
        "        # Index hidden state of last time step\n",
        "        # out.size() --> 100, 28, 100\n",
        "        # out[:, -1, :] --> 100, 100 --> just want last time step hidden states!\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        # out.size() --> 100, 10\n",
        "        return out\n",
        "\n",
        "'''\n",
        "STEP 4: INSTANTIATE MODEL CLASS\n",
        "'''\n",
        "input_dim = 28\n",
        "hidden_dim = 100\n",
        "layer_dim = 2  # ONLY CHANGE IS HERE FROM ONE LAYER TO TWO LAYER\n",
        "output_dim = 10\n",
        "\n",
        "model = RNNModel(input_dim, hidden_dim, layer_dim, output_dim)\n",
        "\n",
        "#######################\n",
        "#  USE GPU FOR MODEL  #\n",
        "#######################\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "'''\n",
        "STEP 5: INSTANTIATE LOSS CLASS\n",
        "'''\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "'''\n",
        "STEP 6: INSTANTIATE OPTIMIZER CLASS\n",
        "'''\n",
        "learning_rate = 0.1\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "'''\n",
        "STEP 7: TRAIN THE MODEL\n",
        "'''\n",
        "\n",
        "# Number of steps to unroll\n",
        "seq_dim = 28\n",
        "\n",
        "iter = 0\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        # Load images as tensors with gradient accumulation abilities\n",
        "        #######################\n",
        "        #  USE GPU FOR MODEL  #\n",
        "        #######################\n",
        "        images = images.view(-1, seq_dim, input_dim).requires_grad_().to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Clear gradients w.r.t. parameters\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass to get output/logits\n",
        "        # outputs.size() --> 100, 10\n",
        "        outputs = model(images)\n",
        "\n",
        "        # Calculate Loss: softmax --> cross entropy loss\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Getting gradients w.r.t. parameters\n",
        "        loss.backward()\n",
        "\n",
        "        # Updating parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        iter += 1\n",
        "\n",
        "        if iter % 500 == 0:\n",
        "            # Calculate Accuracy\n",
        "            correct = 0\n",
        "            total = 0\n",
        "            # Iterate through test dataset\n",
        "            for images, labels in test_loader:\n",
        "                #######################\n",
        "                #  USE GPU FOR MODEL  #\n",
        "                #######################\n",
        "                images = images.view(-1, seq_dim, input_dim).to(device)\n",
        "\n",
        "                # Forward pass only to get logits/output\n",
        "                outputs = model(images)\n",
        "\n",
        "                # Get predictions from the maximum value\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "                # Total number of labels\n",
        "                total += labels.size(0)\n",
        "\n",
        "                # Total correct predictions\n",
        "                #######################\n",
        "                #  USE GPU FOR MODEL  #\n",
        "                #######################\n",
        "                if torch.cuda.is_available():\n",
        "                    correct += (predicted.cpu() == labels.cpu()).sum()\n",
        "                else:\n",
        "                    correct += (predicted == labels).sum()\n",
        "\n",
        "            accuracy = 100 * correct / total\n",
        "\n",
        "            # Print Loss\n",
        "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2M7jTFqWuj8"
      },
      "source": [
        "# Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwHKIcZGWuj8"
      },
      "source": [
        "- **Feedforward Neural Networks** Transition to Recurrent Neural Networks\n",
        "- **RNN Models** in PyTorch\n",
        "    - Model A: 1 Hidden Layer RNN (ReLU)\n",
        "    - Model B: 2 Hidden Layer RNN (ReLU)\n",
        "    - Model C: 2 Hidden Layer RNN (Tanh)\n",
        "- Models Variation in **Code**\n",
        "    - Modifying only step 4\n",
        "- Ways to Expand Models **Capacity**\n",
        "    - More non-linear activation units (**neurons**)\n",
        "    - More hidden **layers**\n",
        "- **Cons** of Expanding Capacity\n",
        "    - Need more **data**\n",
        "    - Does not necessarily mean higher **accuracy**\n",
        "- **GPU** Code\n",
        "    - 2 things on GPU\n",
        "        - **model**\n",
        "        - **tensors with gradient accumulation abilities**\n",
        "    - Modifying only **Step 3, 4 and 7**\n",
        "- **7 Step** Model Building Recap\n",
        "    - Step 1: Load Dataset\n",
        "    - Step 2: Make Dataset Iterable\n",
        "    - **Step 3: Create Model Class**\n",
        "    - **Step 4: Instantiate Model Class**\n",
        "    - Step 5: Instantiate Loss Class\n",
        "    - Step 6: Instantiate Optimizer Class\n",
        "    - **Step 7: Train Model**\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
